\chapter{Concluding Remarks}
\label{chapter: Future Directions}

%conclusion lambanontas upopsi oti o reader kserei ti exei ginei sto thesis
The goal of this final chapter is to conclude this report by reiterating the main contributions of this dissertation, and state a collection of promising ideas for future exploration that stem from the work enclosed in this report.

\section{Conclusion}


In this dissertation, we provide an initial exploration of the opportunity for optimisation of schedules based on the dataset supplied by Royal Mail, as well as an initial step towards the development of an efficient but also robust schedule against uncertainty. Our focus with respect to locating the room for improvement that exists in the historical schedule has been focused on the solution of various \textit{Mixed-Integer Optimisation Problems}, motivated in part by the fact that such formulations enable us to optimised various aspects of the historical schedules. Our goal in optimising those aspects of the historical schedules is to provide solutions for improvements inside a sphere of different factors ranging from employee quality of life, to cost-savings for the company.


\vspace{\baselineskip}
\noindent
In Section \ref{section:Makespan Scheduling-content} of Chapter \ref{chapter: 2-Evaluating Royal Mail Historical Data}, the solution of the Makespan Scheduling formulation provides us with a schedule that featured a minimised makespan. This translates to a more balanced schedule that will prevent employees working overtimes hence improving their general quality of life at work. The following model involved a formulation that attempted to minimise the number of duties required to execute the workload at hand. As seen in Sections \ref{section:minimise duties}-\ref{section: maximise blocks} the solutions provided, outlined a series of schedules that improved on the current schedule both on the employee quality of life and company cost-savings fronts. Namely, the schedules generated by formulation (\ref{equation: Minimise Duties}) minimised the number of duties required. Consequently, the majority of employees could afford to work marginally less, since there were less duties to be completed, and concurrently, Royal Mail could have cost-savings from the reduction in duties since it might possible to place some willing employees to a part-time work schedule. Similarly, formulation (\ref{equation: M3}) maximised the number of blocks that can be processed as we decrease the maximum duty length of the schedule. Our findings indicated that we can generally afford a reduction in the maximum duty length without impacting our processing capacity significantly. Hence, provided Royal Mail is able to implement such schedules with a reduction in the maximum duty length we will have generated an improvement in the quality of life of employees as well as possibility for cost-saving by placing employees on part-time duties.

\vspace{\baselineskip}
\noindent
Finally in Chapter \ref{chapter:Benchmark Instances} we make the first steps towards the formulation of a schedule that is concurrently efficient with respect to the makespan criterion but also remains robust against uncertainty. We start by applying uncertainty components of various sizes to the schedule generated through formulation (\ref{equation: Makespan Scheduling}) of Section \ref{section:Makespan Scheduling-content}. We then optimise those schedules with the Makespan Scheduling formulation. We then compare the optimised disturbed schedules with the recovered version of the nominal. We repeat the same process for schedules generated from two new formulations, the lexicographic and completion time squared models. In the end, we compare all three schedules and determine that the schedule that stems from the lexicographic optimisation is the most robust, and makes the smallest compromise in its makespan efficiency. 

\section{Future Directions}
We conclude this final chapter by enclosing directions for future exploration that were deemed to be worthwhile for further research, upon conversation with our \textit{industrial liaison}, Royal Mail. These ideas are largely an extrapolation of the work presented in this dissertation in the direction of a more practical application of the ideas developed in this report. The fulfilling of the directions outlined below would render our solutions more realistically applicable from the perspective of Royal Mail, since they involve the addition of practical constraints faced by Royal Mail. In contrast the work of this dissertation is largely theoretical and is hopes to discover the theoretical boundaries for optimisation that exist in the context of the problem that we have studied. 

\subsection*{Scheduling Meal-Reliefs}
\label{section: Addition of the Meal Relief Constraint}
The first direction for future investigation concerns the provision of schedules that comply with the Meal-Relief constraint enforced by EU regulations around \textbf{driving} and \textbf{working time directives}, as seen in Appendix \ref{section: EU rules}. Meal-Reliefs are one of the activities observed in the data, as seen in Chapter \ref{chapter: Problem Definition}. However, for the purposes of the Meal-Relief constraint, they are considered a special kind of activity since their location inside a schedule dictates whether the overall schedule is compliant with the EU regulations. Consequently, the decision regarding the time that these activities are scheduled involves the addition of a new type of scheduling constraint. 

\vspace{\baselineskip}
\noindent
In practice, this involves the addition of two new scheduling constraints to our models, one for the driving time and one for the working time directives. These two constraints will render certain schedules infeasible if they do not satisfy both directives. 

\vspace{\baselineskip}
\noindent
Even though it is extremely interesting to explore from an algorithmic point of view, after consulting with our industrial liaison, we determined that it was out of scope for the purposes of this dissertation. Our goal through this project is to provide schedules that explore the boundaries of what is possible in the context of this problem. In contrast, choosing to implement the Meal-Relief constraint would allow us to search for efficient schedules from within a rather narrow subset of the overall feasible set, hence preventing us from approaching the boundaries of global optimally. Moreover, as we were informed by the Royal Mail Scheduling staff, enforcing the Meal-Relief constraint, is largely an \textit{ad-hoc} operation that they tend to perform at the last stage of the schedules' design, which also takes into account the various peculiarities related to each MC's fleet of drivers. For instance, drivers at each MC may be accustomed to taking their Meal-Relief breaks only at specific locations and at specific times within their duty. Hence, enforcing a high-level version of the Meal-Relief constraint that does not take into account those minor but important details would not prove effective in reality. As a result, focusing on further exploring this aspect of the problem without considering such human factors that are not captured by the dataset, and can only be examined within Royal Mail's infrastructure was determined to be not worthwhile pursuing at this stage of the project. 

\vspace{\baselineskip}
\noindent
Provided, that we can gain access to this information and consult with each MC's stakeholders to take into account their requests, and implement them in the form of various optimisation constraints, the enforcement of the Meal-Relief constraint can be reduced down to a mere addition of a constraint to our model. The \textbf{working time directive} is to be respected by making sure that the \textbf{duration} of a \textit{duty} is compliant with the regulation. On the contrary the \textbf{driving time directive} is examined at the \textbf{block} level, and has to be respected between adjacent blocks.  The collection of travel legs featured within each block are those that determine the feasibility component, regarding the \textbf{driving time} regulation. 

\subsubsection*{Driving Time Directive}

\vspace{\baselineskip}
\noindent
Ideally, it should take place at the end of a shift, at which point the \textit{driving time} limit has been exhausted. However, in the case that prior blocks have consumed a large part of the 4.5 hour driving buffer such that the following block would violate the regulation, the meal relief has to be brought forward, and scheduled between the blocks.   

\subsubsection*{Working Time Directive}

 Technically, \texttt{Meal-Relief} activities, are at the moment actually scheduled inside the blocks featured in our proposed schedules since as explained in the Data Cleaning section (\ref{section: Data Cleaning}) the \texttt{Meal Relief} activity was one of the \textbf{useful} activities that we preserved insider our blocks during the Data Cleaning procedures we followed. Hence, as far the implementation of the Meal Relief Constraint is concerned, rendering our \textit{proposed schedules} legal with respect to this constraint is simply a matter of moving the \texttt{Meal Relief} activities in the right place within the space of a duty. 
 
 \vspace{\baselineskip}
\noindent
 Moreover, we anticipate that the addition of these constrains to our models, will make the process of finding an optimal solution less complicated, as opposed to without them since we will be essentially \textit{tightening our feasible space}, hence it will relatively more straightforward to obtain an optimal solution. 

\vspace{\baselineskip}
\noindent
Upon conversation with our industrial liaison (Royal Mail), we decided to forego the desire to explore the \textbf{Meal Relief} constraint, as it was deemed merely a practical contribution that would not particularly expand the theoretical frontier for what is possible. 

\subsection*{Vehicle Routing Considerations}
As was discussed in the introductory chapters we do not particularly focus on the \textit{Vehicle Routing} component of the problem. By additionally implementing the \textit{routing} component, we wish to extend the aspects of the problem captured in our model, a critical sub-problem in the majority of distribution network problems.

\vspace{\baselineskip}
\noindent
We briefly investigated a glimpse of the routing aspect of the problem in section \ref{section: Pre-emptive}, where the implementation of the pre-emptive philosophy did in fact result into a \textit{re-routing} of the routes followed by drivers. However, numerous experiments that are specifically focused on the solution of the \textit{routing} problem are required to acquire an accurate and insightful understanding of the problem through this point of view.

\vspace{\baselineskip}
\noindent
 As explained, in the Data Cleaning section (\ref{section: Data Cleaning}), we eliminated certain attributes from each data entry of the dataset that were not helpful when looking at the problem from the \textit{scheduling perspective.} As seen in Appendix \ref{subsection: Eliminated Attributes} one out of those eliminated attributes, consisted of information regarding the distance between locations visited by the HGVs. In solving this problem, one could use this information and form the problem through the concept of a \textbf{graph}. \textit{Edges}, of this graph would represent the \textit{time} and \textit{distance} between locations and \textbf{nodes} would represent the various external locations themselves. Plotting these graphs, one could then rearrange the \textbf{routing} aspect of the problem to make efficiency gains.
 
\subsection*{Incorporating Deadline Constraints}
During the initial data cleaning stages of the project we observed the existence of certain blocks that contained trips that were bound with a deadline with respect to the time of their completion. Namely, such trips involve the delivery of time-sensitive packages. As explained in Section \ref{section: Data Cleaning} of Chapter \ref{chapter: Problem Definition} this packages often refer to trips to the airport, which are by nature time-constrained.

\vspace{\baselineskip}
\noindent
However, as explained in Section \ref{section: Data Cleaning} we decided to ignore such data that is related to \textbf{time-constrained packages} and determine it us out of scope for the purposes of our project. The rationale behind this decision is founded in the fact that to satisfy our objective of finding the available room for optimisation we demand total freedom as far as our ability to move the blocks from duty to duty.

\vspace{\baselineskip}
\noindent
Nevertheless, the exploration of such time-constrained trips would be of significant interest both for researchers but also for Royal Mail. For researchers such a task poses great methodological potential. Namely, these time-sensitive round-trips would place certain blocks rigidly inside the spectrum of a duty such that the solver cannot relocate them. In practice, it would be implemented as an additional optimisation constraint. As our result, this would further shrink the feasible set allowing the scheduler less room for the exploration of the optimisation bounds. From the perspective of Royal Mail, the incorporation such constraints would be highly valuable since it would make our proposed schedules more realistic. Moreover, those schedules would be easier to implement since Royal Mail's operators would not have to heuristically add those constraints and re-order the duties' sequences so that those blocks are placed rigidly in the right place. 

\subsection*{Incorporating Ellipsoid Uncertainty Sets}
As mentioned in the evaluation chapter (\ref{chapter: Evaluation}) due to the fact the study of uncertainty was a late addition to the topics explored we decided not to proceed with the addition of ellipsoid uncertainty set-based components. However, we believe that the study of the effects the application of an ellipsoid-based uncertainty components is a direction for future research that should definitely be tapped. 

\vspace{\baselineskip}
\noindent
In greater detail, we believe that the ellipsoidal nature of such uncertainty components would introduce an additional methodological interest to our problem. In greater detail, the addition of ellipsoidal uncertainty sets will transform the study of the robustness of the target model\footnote{The model to which the uncertainty component is applied} to the process of solving conic quadratic problems \cite{Ben-Tal2000}. Moreover, the analysis of the effects of ellipsoidal uncertainty sets can be used as a further stepping stone for the approximation of the effects of more complex uncertainty sets\cite{vertsimas}.